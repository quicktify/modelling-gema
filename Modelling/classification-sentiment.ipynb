{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook: Sentiment and Emotion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalasi Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing scikit-learn...\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing imbalanced-learn...\n",
      "Requirement already satisfied: imbalanced-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (3.6.0)\n",
      "All required modules are installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Daftar modul yang diperlukan\n",
    "required_modules = [\n",
    "    'pandas', 'numpy', 'scikit-learn', 'imbalanced-learn',\n",
    "    'Sastrawi', 'matplotlib', 'seaborn'\n",
    "]\n",
    "\n",
    "# Fungsi untuk menginstal modul jika belum ada\n",
    "def install_modules(modules):\n",
    "    for module in modules:\n",
    "        try:\n",
    "            __import__(module)\n",
    "        except ImportError:\n",
    "            print(f\"Installing {module}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", module])\n",
    "\n",
    "# Jalankan instalasi\n",
    "install_modules(required_modules)\n",
    "print(\"All required modules are installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # Ganti import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from multiprocessing import Pool\n",
    "from imblearn.pipeline import Pipeline  # Ganti dengan ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Kolom dataset: ['sentimen', 'emosi', 'ulasan']\n",
      "Contoh data pertama:\n",
      "    sentimen  emosi                                             ulasan\n",
      "0  Negative  Anger  bukan menyenangkan malah bikin kesal hp saya r...\n",
      "1  Negative  Anger  kalo ngak niat bikin gamenya bagus hapus aja d...\n",
      "2  Negative  Anger  makin lama, makin gak jelas dri sblum di updat...\n",
      "3  Negative  Anger  semenjak update sangat sangat buruk setiap mai...\n",
      "4  Negative  Anger                                              burik\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../dataset/dataset_structured.csv')\n",
    "\n",
    "# Pemeriksaan kolom\n",
    "expected_columns = ['sentimen', 'emosi', 'ulasan']\n",
    "if not all(col in df.columns for col in expected_columns):\n",
    "    raise ValueError(f\"Dataset harus memiliki kolom: {expected_columns}\")\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"Kolom dataset:\", df.columns.tolist())\n",
    "print(\"Contoh data pertama:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai preprocessing teks...\n",
      "Preprocessing selesai. Contoh data setelah preprocessing:\n",
      "                                              ulasan  \\\n",
      "0  bukan menyenangkan malah bikin kesal hp saya r...   \n",
      "1  kalo ngak niat bikin gamenya bagus hapus aja d...   \n",
      "2  makin lama, makin gak jelas dri sblum di updat...   \n",
      "3  semenjak update sangat sangat buruk setiap mai...   \n",
      "4                                              burik   \n",
      "\n",
      "                                      Cleaned_Review  \n",
      "0  senang bikin kesal hp realme c ngeblank hitam ...  \n",
      "1  niat bikin gamenya bagus hapus gamenya narik m...  \n",
      "2  sblum update game update suka main bug tlong b...  \n",
      "3  semenjak update buruk main bareng putus sinyal...  \n",
      "4                                              jelek  \n"
     ]
    }
   ],
   "source": [
    "# Import library yang diperlukan\n",
    "import pandas as pd\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Load slang dictionary dari file\n",
    "slang_df = pd.read_csv('../dataset/slang_indo.csv', header=None, names=['slang', 'formal'])\n",
    "slang_dict = dict(zip(slang_df['slang'], slang_df['formal']))\n",
    "\n",
    "# Load stopwords dari file\n",
    "with open('../dataset/stopwords-id.txt', 'r') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "# Tambahkan slang tambahan yang belum ada di file\n",
    "additional_slang = {\n",
    "    'burik': 'jelek',\n",
    "    'anjs': 'anjing',\n",
    "    'goblok': 'bodoh',\n",
    "    'kontol': 'kasar',\n",
    "    'sialan': 'kasar',\n",
    "    'anjg': 'anjing',\n",
    "    'bgs': 'bagus',\n",
    "    'bgt': 'banget',\n",
    "    'bnyk': 'banyak',\n",
    "    'bsk': 'besok',\n",
    "    'byk': 'banyak',\n",
    "    'dmn': 'dimana',\n",
    "    'gmn': 'gimana',\n",
    "    'jd': 'jadi',\n",
    "    'jg': 'juga',\n",
    "    'klo': 'kalau',\n",
    "    'kyk': 'seperti',\n",
    "    'lg': 'lagi',\n",
    "    'mau': 'ingin',\n",
    "    'mngkn': 'mungkin',\n",
    "    'msh': 'masih',\n",
    "    'nggak': 'tidak',\n",
    "    'ngga': 'tidak',\n",
    "    'pdhl': 'padahal',\n",
    "    'pny': 'punya',\n",
    "    'sbnrnya': 'sebenarnya',\n",
    "    'sdh': 'sudah',\n",
    "    'skrg': 'sekarang',\n",
    "    'sm': 'sama',\n",
    "    'spt': 'seperti',\n",
    "    'sy': 'saya',\n",
    "    'tdk': 'tidak',\n",
    "    'tp': 'tapi',\n",
    "    'udh': 'sudah',\n",
    "    'utk': 'untuk',\n",
    "    'yg': 'yang'\n",
    "}\n",
    "slang_dict.update(additional_slang)\n",
    "\n",
    "# Inisialisasi stemmer Sastrawi\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def normalize_slang(text):\n",
    "    \"\"\"Normalisasi slang words ke bentuk formal\"\"\"\n",
    "    words = text.split()\n",
    "    return ' '.join(slang_dict.get(word, word) for word in words)\n",
    "\n",
    "def remove_repeated_words(text):\n",
    "    \"\"\"Menghapus kata yang diulang berurutan\"\"\"\n",
    "    words = text.split()\n",
    "    result = []\n",
    "    for i in range(len(words)):\n",
    "        if i == 0 or words[i] != words[i-1]:\n",
    "            result.append(words[i])\n",
    "    return ' '.join(result)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan preprocessing teks\n",
    "    \"\"\"\n",
    "    # Ubah ke huruf kecil\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Hapus kode transaksi\n",
    "    text = re.sub(r'\\b\\d+[a-zA-Z]+\\d+\\b', '', text)\n",
    "    \n",
    "    # Hapus URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Hapus tanda baca dan karakter khusus\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Hapus angka\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Hapus spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Normalisasi slang\n",
    "    text = normalize_slang(text)\n",
    "    \n",
    "    # Hapus kata yang diulang\n",
    "    text = remove_repeated_words(text)\n",
    "    \n",
    "    # Hapus stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    # Stemming\n",
    "    text = stemmer.stem(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Terapkan preprocessing pada kolom 'ulasan'\n",
    "print(\"Memulai preprocessing teks...\")\n",
    "df['Cleaned_Review'] = df['ulasan'].apply(preprocess_text)\n",
    "print(\"Preprocessing selesai. Contoh data setelah preprocessing:\")\n",
    "print(df[['ulasan', 'Cleaned_Review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemisahan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai pemisahan data...\n",
      "Data sentimen - Training samples: 16920\n",
      "Data sentimen - Testing samples: 4230\n",
      "Data emosi - Training samples: 16920\n",
      "Data emosi - Testing samples: 4230\n"
     ]
    }
   ],
   "source": [
    "# Pemisahan Data\n",
    "print(\"Memulai pemisahan data...\")\n",
    "\n",
    "# Untuk sentimen\n",
    "X_sentiment = df['Cleaned_Review']  # Menggunakan kolom yang sudah di-preprocess\n",
    "y_sentiment = df['sentimen']\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent = train_test_split(\n",
    "    X_sentiment, y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment\n",
    ")\n",
    "\n",
    "# Untuk emosi\n",
    "X_emotion = df['Cleaned_Review']  # Menggunakan kolom yang sudah di-preprocess\n",
    "y_emotion = df['emosi']\n",
    "X_train_emo, X_test_emo, y_train_emo, y_test_emo = train_test_split(\n",
    "    X_emotion, y_emotion, test_size=0.2, random_state=42, stratify=y_emotion\n",
    ")\n",
    "\n",
    "print(\"Data sentimen - Training samples:\", len(X_train_sent))\n",
    "print(\"Data sentimen - Testing samples:\", len(X_test_sent))\n",
    "print(\"Data emosi - Training samples:\", len(X_train_emo))\n",
    "print(\"Data emosi - Testing samples:\", len(X_test_emo))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembuatan Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline untuk sentimen dan emosi telah dibuat.\n"
     ]
    }
   ],
   "source": [
    "# Membuat pipeline untuk kedua tugas:\n",
    "# - Ekstraksi fitur menggunakan `TfidfVectorizer`.\n",
    "# - Penanganan ketidakseimbangan kelas menggunakan `SMOTE`.\n",
    "# - Model SVM dengan parameter probabilitas.\n",
    "\n",
    "#%%\n",
    "# Pipeline untuk sentimen\n",
    "sentiment_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "# Pipeline untuk emosi\n",
    "emotion_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "print(\"Pipeline untuk sentimen dan emosi telah dibuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai tuning hyperparameter...\n",
      "Tuning model sentimen...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 60 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 562, in _fit\n    self._validate_steps()\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 339, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     13\u001b[39m grid_search_sent = GridSearchCV(\n\u001b[32m     14\u001b[39m     sentiment_pipeline, \n\u001b[32m     15\u001b[39m     param_grid, \n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Fit model sentimen\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mgrid_search_sent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters for sentiment:\u001b[39m\u001b[33m\"\u001b[39m, grid_search_sent.best_params_)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest score for sentiment:\u001b[39m\u001b[33m\"\u001b[39m, grid_search_sent.best_score_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1001\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    996\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    997\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    998\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m    999\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1004\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:517\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    511\u001b[39m     all_fits_failed_message = (\n\u001b[32m    512\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    520\u001b[39m     some_fits_failed_message = (\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 60 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 562, in _fit\n    self._validate_steps()\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 339, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't\n"
     ]
    }
   ],
   "source": [
    "# Tuning Hyperparameter\n",
    "print(\"\\nMemulai tuning hyperparameter...\")\n",
    "\n",
    "# Definisikan parameter grid\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "    'tfidf__max_features': [3000, 5000]\n",
    "}\n",
    "\n",
    "# Grid Search untuk sentimen\n",
    "print(\"Tuning model sentimen...\")\n",
    "grid_search_sent = GridSearchCV(\n",
    "    sentiment_pipeline, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted', \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit model sentimen\n",
    "grid_search_sent.fit(X_train_sent, y_train_sent)\n",
    "print(\"Best parameters for sentiment:\", grid_search_sent.best_params_)\n",
    "print(\"Best score for sentiment:\", grid_search_sent.best_score_)\n",
    "\n",
    "# Grid Search untuk emosi\n",
    "print(\"\\nTuning model emosi...\")\n",
    "grid_search_emo = GridSearchCV(\n",
    "    emotion_pipeline, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted', \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit model emosi\n",
    "grid_search_emo.fit(X_train_emo, y_train_emo)\n",
    "print(\"Best parameters for emotion:\", grid_search_emo.best_params_)\n",
    "print(\"Best score for emotion:\", grid_search_emo.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengevaluasi model pada data testing:\n",
    "# - Classification report untuk precision, recall, dan F1-score.\n",
    "# - Confusion matrix untuk visualisasi kesalahan klasifikasi.\n",
    "\n",
    "# Sentimen\n",
    "y_pred_sent = grid_search_sent.predict(X_test_sent)\n",
    "print(\"Classification Report for Sentiment:\")\n",
    "print(classification_report(y_test_sent, y_pred_sent))\n",
    "\n",
    "# Emosi\n",
    "y_pred_emo = grid_search_emo.predict(X_test_emo)\n",
    "print(\"Classification Report for Emotion:\")\n",
    "print(classification_report(y_test_emo, y_pred_emo))\n",
    "\n",
    "# Visualisasi Confusion Matrix untuk Sentimen\n",
    "cm_sent = confusion_matrix(y_test_sent, y_pred_sent)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_sent, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Sentiment Classification')\n",
    "plt.savefig('cm_sentiment.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualisasi Confusion Matrix untuk Emosi\n",
    "cm_emo = confusion_matrix(y_test_emo, y_pred_emo)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_emo, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Emotion Classification')\n",
    "plt.savefig('cm_emotion.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_model.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search_sent.best_estimator_, f)\n",
    "\n",
    "with open('emotion_model.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search_emo.best_estimator_, f)\n",
    "\n",
    "print(\"Model telah disimpan sebagai 'sentiment_model.pkl' dan 'emotion_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediksi Ulasan Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memprediksi sentimen dan emosi dari ulasan baru.\n",
    "# Contoh ulasan: \"Aplikasi ini burik banget, gk bisa login!\"\n",
    "\n",
    "def predict_new_review(review):\n",
    "    cleaned_review = preprocess_text(review)\n",
    "    sentiment = grid_search_sent.best_estimator_.predict([cleaned_review])[0]\n",
    "    emotion = grid_search_emo.best_estimator_.predict([cleaned_review])[0]\n",
    "    return {'Sentiment': sentiment, 'Emotion': emotion}\n",
    "\n",
    "# Contoh penggunaan\n",
    "new_review = \"Aplikasi ini burik banget, gk bisa login!\"\n",
    "prediction = predict_new_review(new_review)\n",
    "print(\"Prediction for new review:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
