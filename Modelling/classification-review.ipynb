{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook: Sentiment and Emotion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalasi Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing scikit-learn...\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Installing imbalanced-learn...\n",
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (2.2.0)\n",
      "All required modules are installed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Daftar modul yang diperlukan\n",
    "required_modules = [\n",
    "    'pandas', 'numpy', 'scikit-learn', 'imbalanced-learn',\n",
    "    'Sastrawi', 'matplotlib', 'seaborn'\n",
    "]\n",
    "\n",
    "# Fungsi untuk menginstal modul jika belum ada\n",
    "def install_modules(modules):\n",
    "    for module in modules:\n",
    "        try:\n",
    "            __import__(module)\n",
    "        except ImportError:\n",
    "            print(f\"Installing {module}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", module])\n",
    "\n",
    "# Jalankan instalasi\n",
    "install_modules(required_modules)\n",
    "print(\"All required modules are installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Kolom dataset: ['sentimen', 'emosi', 'ulasan']\n",
      "Contoh data pertama:\n",
      "    sentimen  emosi                                             ulasan\n",
      "0  Negative  Anger  bukan menyenangkan malah bikin kesal hp saya r...\n",
      "1  Negative  Anger  kalo ngak niat bikin gamenya bagus hapus aja d...\n",
      "2  Negative  Anger  makin lama, makin gak jelas dri sblum di updat...\n",
      "3  Negative  Anger  semenjak update sangat sangat buruk setiap mai...\n",
      "4  Negative  Anger                                              burik\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('dataset/dataset_structured.csv')\n",
    "\n",
    "# Pemeriksaan kolom\n",
    "expected_columns = ['sentimen', 'emosi', 'ulasan']\n",
    "if not all(col in df.columns for col in expected_columns):\n",
    "    raise ValueError(f\"Dataset harus memiliki kolom: {expected_columns}\")\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"Kolom dataset:\", df.columns.tolist())\n",
    "print(\"Contoh data pertama:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing selesai. Contoh data setelah preprocessing:\n",
      "                                               ulasan  \\\n",
      "0  bukan menyenangkan malah bikin kesal hp saya r...   \n",
      "1  kalo ngak niat bikin gamenya bagus hapus aja d...   \n",
      "2  makin lama, makin gak jelas dri sblum di updat...   \n",
      "3  semenjak update sangat sangat buruk setiap mai...   \n",
      "4                                              burik   \n",
      "\n",
      "                                      Cleaned_Review  \n",
      "0  bukan senang malah bikin kesal hp saya realme ...  \n",
      "1  kalo ngak niat bikin gamenya bagus hapus aja d...  \n",
      "2  makin lama makin tidak jelas dri sblum di upda...  \n",
      "3  semenjak update sangat sangat buruk tiap main ...  \n",
      "4                                              jelek  \n"
     ]
    }
   ],
   "source": [
    "# Kamus normalisasi slang bahasa Indonesia\n",
    "slang_dict = {\n",
    "    'gk': 'tidak', 'gak': 'tidak', 'bgt': 'banget', 'burik': 'jelek',\n",
    "    'anjs': 'anjing', 'goblok': 'bodoh', 'kontol': 'kasar', 'sialan': 'kasar'\n",
    "}\n",
    "\n",
    "def normalize_slang(text):\n",
    "    words = text.split()\n",
    "    return ' '.join(slang_dict.get(word, word) for word in words)\n",
    "\n",
    "# Inisialisasi stemmer Sastrawi\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Ubah ke huruf kecil\n",
    "    text = text.lower()\n",
    "    # Hapus kode transaksi\n",
    "    text = re.sub(r'\\b\\d+[a-zA-Z]+\\d+\\b', '', text)\n",
    "    # Hapus tanda baca dan karakter khusus\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Normalisasi slang\n",
    "    text = normalize_slang(text)\n",
    "    # Stemming\n",
    "    text = stemmer.stem(text)\n",
    "    return text\n",
    "\n",
    "# Terapkan preprocessing pada kolom 'ulasan'\n",
    "df['Cleaned_Review'] = df['ulasan'].apply(preprocess_text)\n",
    "print(\"Preprocessing selesai. Contoh data setelah preprocessing:\\n\", df[['ulasan', 'Cleaned_Review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemisahan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sentimen - Training samples: 16920\n",
      "Data sentimen - Testing samples: 4230\n",
      "Data emosi - Training samples: 16920\n",
      "Data emosi - Testing samples: 4230\n"
     ]
    }
   ],
   "source": [
    "# Memisahkan data untuk dua tugas:\n",
    "# - Klasifikasi sentimen (menggunakan `sentimen` sebagai target).\n",
    "# - Klasifikasi emosi (menggunakan `emosi` sebagai target).\n",
    "# Data dibagi 80% training dan 20% testing dengan stratifikasi.\n",
    "\n",
    "# Untuk sentimen\n",
    "X_sentiment = df['Cleaned_Review']\n",
    "y_sentiment = df['sentimen']\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent = train_test_split(\n",
    "    X_sentiment, y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment\n",
    ")\n",
    "\n",
    "# Untuk emosi\n",
    "X_emotion = df['Cleaned_Review']\n",
    "y_emotion = df['emosi']\n",
    "X_train_emo, X_test_emo, y_train_emo, y_test_emo = train_test_split(\n",
    "    X_emotion, y_emotion, test_size=0.2, random_state=42, stratify=y_emotion\n",
    ")\n",
    "\n",
    "print(\"Data sentimen - Training samples:\", len(X_train_sent))\n",
    "print(\"Data sentimen - Testing samples:\", len(X_test_sent))\n",
    "print(\"Data emosi - Training samples:\", len(X_train_emo))\n",
    "print(\"Data emosi - Testing samples:\", len(X_test_emo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembuatan Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline untuk sentimen dan emosi telah dibuat.\n"
     ]
    }
   ],
   "source": [
    "# Membuat pipeline untuk kedua tugas:\n",
    "# - Ekstraksi fitur menggunakan `TfidfVectorizer`.\n",
    "# - Penanganan ketidakseimbangan kelas menggunakan `SMOTE`.\n",
    "# - Model SVM dengan parameter probabilitas.\n",
    "\n",
    "#%%\n",
    "# Pipeline untuk sentimen\n",
    "sentiment_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "# Pipeline untuk emosi\n",
    "emotion_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "print(\"Pipeline untuk sentimen dan emosi telah dibuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment and emotion pipelines are defined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3919.74s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3919.75s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3919.77s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3919.80s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3919.81s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3919.83s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3919.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3919.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 60 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 339, in _fit\n    self._validate_steps()\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 230, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/la/Documents/Semester 6/Proyek Kekhususan/modelling-gema/classification-review.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Grid Search untuk sentimen\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m grid_search_sent \u001b[39m=\u001b[39m GridSearchCV(sentiment_pipeline, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1_weighted\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m grid_search_sent\u001b[39m.\u001b[39mfit(X_train_sent, y_train_sent)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameters for sentiment:\u001b[39m\u001b[39m\"\u001b[39m, grid_search_sent\u001b[39m.\u001b[39mbest_params_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Grid Search untuk emosi\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    849\u001b[0m     )\n\u001b[0;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_score)\n\u001b[1;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 60 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 339, in _fit\n    self._validate_steps()\n  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 230, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't\n"
     ]
    }
   ],
   "source": [
    "# Melakukan Grid Search untuk menemukan parameter terbaik.\n",
    "# **Pastikan sel \"Pembuatan Pipeline\" sudah dijalankan untuk mendefinisikan `sentiment_pipeline` dan `emotion_pipeline`.**\n",
    "\n",
    "#%%\n",
    "# Pemeriksaan apakah pipeline tersedia\n",
    "try:\n",
    "    sentiment_pipeline\n",
    "    emotion_pipeline\n",
    "    print(\"Sentiment and emotion pipelines are defined.\")\n",
    "except NameError:\n",
    "    raise NameError(\"Pipeline not defined. Please run the 'Pembuatan Pipeline' cell first.\")\n",
    "\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "    'tfidf__max_features': [3000, 5000]\n",
    "}\n",
    "\n",
    "# Grid Search untuk sentimen\n",
    "grid_search_sent = GridSearchCV(sentiment_pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_sent.fit(X_train_sent, y_train_sent)\n",
    "print(\"Best parameters for sentiment:\", grid_search_sent.best_params_)\n",
    "\n",
    "# Grid Search untuk emosi\n",
    "grid_search_emo = GridSearchCV(emotion_pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_emo.fit(X_train_emo, y_train_emo)\n",
    "print(\"Best parameters for emotion:\", grid_search_emo.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/la/Documents/Semester 6/Proyek Kekhususan/modelling-gema/classification-review.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Mengevaluasi model pada data testing:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# - Classification report untuk precision, recall, dan F1-score.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# - Confusion matrix untuk visualisasi kesalahan klasifikasi.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Sentimen\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_pred_sent \u001b[39m=\u001b[39m grid_search_sent\u001b[39m.\u001b[39mpredict(X_test_sent)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report for Sentiment:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Semester%206/Proyek%20Kekhususan/modelling-gema/classification-review.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test_sent, y_pred_sent))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:498\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39m@available_if\u001b[39m(_estimator_has(\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    480\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    481\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \n\u001b[1;32m    483\u001b[0m \u001b[39m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39m        the best found parameters.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    499\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[1;32m   1386\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1387\u001b[0m     ]\n\u001b[1;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1390\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Mengevaluasi model pada data testing:\n",
    "# - Classification report untuk precision, recall, dan F1-score.\n",
    "# - Confusion matrix untuk visualisasi kesalahan klasifikasi.\n",
    "\n",
    "# Sentimen\n",
    "y_pred_sent = grid_search_sent.predict(X_test_sent)\n",
    "print(\"Classification Report for Sentiment:\")\n",
    "print(classification_report(y_test_sent, y_pred_sent))\n",
    "\n",
    "# Emosi\n",
    "y_pred_emo = grid_search_emo.predict(X_test_emo)\n",
    "print(\"Classification Report for Emotion:\")\n",
    "print(classification_report(y_test_emo, y_pred_emo))\n",
    "\n",
    "# Visualisasi Confusion Matrix untuk Sentimen\n",
    "cm_sent = confusion_matrix(y_test_sent, y_pred_sent)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_sent, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Sentiment Classification')\n",
    "plt.savefig('cm_sentiment.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualisasi Confusion Matrix untuk Emosi\n",
    "cm_emo = confusion_matrix(y_test_emo, y_pred_emo)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_emo, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Emotion Classification')\n",
    "plt.savefig('cm_emotion.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_model.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search_sent.best_estimator_, f)\n",
    "\n",
    "with open('emotion_model.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search_emo.best_estimator_, f)\n",
    "\n",
    "print(\"Model telah disimpan sebagai 'sentiment_model.pkl' dan 'emotion_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediksi Ulasan Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memprediksi sentimen dan emosi dari ulasan baru.\n",
    "# Contoh ulasan: \"Aplikasi ini burik banget, gk bisa login!\"\n",
    "\n",
    "def predict_new_review(review):\n",
    "    cleaned_review = preprocess_text(review)\n",
    "    sentiment = grid_search_sent.best_estimator_.predict([cleaned_review])[0]\n",
    "    emotion = grid_search_emo.best_estimator_.predict([cleaned_review])[0]\n",
    "    return {'Sentiment': sentiment, 'Emotion': emotion}\n",
    "\n",
    "# Contoh penggunaan\n",
    "new_review = \"Aplikasi ini burik banget, gk bisa login!\"\n",
    "prediction = predict_new_review(new_review)\n",
    "print(\"Prediction for new review:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
